[mode]
model_name = mt-lstm-crf
train_model = True
save_model = True

[data]
dataset_folder = /home/john/dev/Saber/datasets/BC2GM_BIO, /home/john/dev/Saber/datasets/AnatEM_BIO, /home/john/dev/Saber/datasets/BC5CDR_BIO, /home/john/dev/Saber/datasets/BioNLP09_BIO, /home/john/dev/Saber/datasets/BioNLP11EPI_BIO, /home/john/dev/Saber/datasets/BioNLP11ID_BIO, /home/john/dev/Saber/datasets/BioNLP13CG_BIO, /home/john/dev/Saber/datasets/BioNLP13GE_BIO, /home/john/dev/Saber/datasets/CRAFT_BIO, /home/john/dev/Saber/datasets/Ex-PTM_BIO, /home/john/dev/Saber/datasets/JNLPBA_BIO, /home/john/dev/Saber/datasets/Linnaeus_BIO, /home/john/dev/Saber/datasets/NCBI-Disease_BIO, /home/john/dev/Saber/datasets/MLEE_BIO
output_folder = /home/john/dev/Saber/output/pretrained_models
pretrained_model_weights = 
pretrained_embeddings = /home/john/dev/Saber/word_embeddings/wikipedia-pubmed-and-PMC-w2v.bin

[model]
word_embed_dim = 200
char_embed_dim = 30

[training]
optimizer = nadam
activation = relu
grad_norm = 1.0
learning_rate = 0.0
decay = 0.0
dropout_rate = 0.3, 0.3, 0.1
batch_size = 32
k_folds = 20
epochs = 50
criteria = exact

[advanced]
verbose = True
debug = False
tensorboard = False
replace_rare_tokens = True
fine_tune_word_embeddings = False
variational_dropout = True

